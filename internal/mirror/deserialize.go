package mirror

import (
	"archive/tar"
	"bufio"
	"bytes"
	"compress/gzip"
	"context"
	"encoding/json"
	"errors"
	"fmt"
	"io"
	"log/slog"
	"os"
	"path"
	"strconv"

	"github.com/klauspost/compress/zstd"
	"github.com/opencontainers/go-digest"
	ocispec "github.com/opencontainers/image-spec/specs-go/v1"
	"oras.land/oras-go/v2/content"
	"oras.land/oras-go/v2/content/memory"
	"oras.land/oras-go/v2/errdef"
	"oras.land/oras-go/v2/registry"

	"gitlab.com/act3-ai/asce/data/tool/internal/mirror/encoding"
	"gitlab.com/act3-ai/asce/data/tool/internal/orasutil"
	"gitlab.com/act3-ai/asce/data/tool/internal/print"
	"gitlab.com/act3-ai/asce/data/tool/internal/ui"
	"gitlab.com/act3-ai/asce/go-common/pkg/ioutil"
	"gitlab.com/act3-ai/asce/go-common/pkg/logger"
)

// DeserializeOptions specify the requirements to run the mirror deserialize command.
type DeserializeOptions struct {
	DestStorage         content.Storage
	DestTargetReference registry.Reference
	SourceFile          string
	BufferSize          int
	DryRun              bool
	RootUI              *ui.Task
	Strict              bool
	Log                 *slog.Logger
}

// Deserialize will extract the oci artifacts from a tar file (generated by ace-dt mirror serialize) to a destination target.
func Deserialize(ctx context.Context, opts DeserializeOptions) (ocispec.Descriptor, error) { //nolint:gocognit

	// open input file for reading
	src, err := os.Open(opts.SourceFile)
	if err != nil {
		return ocispec.Descriptor{}, fmt.Errorf("error opening the source file provided: %w", err)
	}
	defer src.Close()

	// Read the first few bytes to determine if it's compressed
	head := make([]byte, 10)
	var sr io.Reader

	if opts.BufferSize != 0 {
		sr = bufio.NewReaderSize(src, opts.BufferSize)
	} else {
		// we create a large buffer size
		sr = bufio.NewReaderSize(src, 64*1024) // 64 KB buffer
	}
	cw := new(ioutil.WriterCounter)

	// Read the initial bytes into the buffer
	n, err := io.ReadFull(sr, head)
	if err != nil && !errors.Is(err, io.EOF) && !errors.Is(err, io.ErrUnexpectedEOF) {
		return ocispec.Descriptor{}, fmt.Errorf("failed to read header: %w", err)
	}

	// Create a multi-reader to read from the buffer and the file
	r := io.MultiReader(bytes.NewReader(head[:n]), sr)

	switch {
	case isGzip(head):
		gr, err := gzip.NewReader(r)
		if err != nil {
			return ocispec.Descriptor{}, fmt.Errorf("creating gzip reader: %w", err)
		}
		sr = gr
	case isZstd(head):
		zr, err := zstd.NewReader(r)
		if err != nil {
			return ocispec.Descriptor{}, fmt.Errorf("creating zstd reader: %w", err)
		}
		sr = zr
	default:
		// assume regular tar file
		sr = r
	}

	tr := tar.NewReader(io.TeeReader(sr, cw))

	// if opts.DestStorage is a orasutil.CachedGraphTarget, then both the remoteStorage
	// and the cacheStorage share the same underlying cache. The following allows us to not only
	// easily push to the cache exclusively, but also fallback to an in-memory cache
	// should we not already have the expected cached remote target interface.
	remoteStorage := opts.DestStorage
	var cacheStorage content.Storage
	cgt, ok := opts.DestStorage.(*orasutil.CachedGraphTarget)
	if ok {
		cacheStorage = cgt.Cache
	} else {
		cacheStorage = memory.New()
	}

	// add to the remote existence cache (optimization)
	remoteStorage = orasutil.NewExistenceCachedStorage(remoteStorage)

	// Disable Push() and Tag()
	if opts.DryRun {
		remoteStorage = orasutil.NewNoPushStorage(remoteStorage)
	}

	tracker := encoding.NewTaggableTracker(remoteStorage, cacheStorage)
	tracker.FindSuccessors = encoding.Successors

	type stage int
	const (
		stageUndefined stage = iota
		stageOCILayout
		stageIndexJSON
		stageBlob
	)
	currentStage := stageOCILayout
	var indexDesc *ocispec.Descriptor

	task := opts.RootUI.SubTask("Deserializing")
	defer task.Complete()

	progress := opts.RootUI.SubTaskWithProgress("Writing archive to destination registry")
	defer progress.Complete()

	// consume the tar data
	for {
		hdr, err := tr.Next()
		if errors.Is(err, io.EOF) {
			break
		}
		if err != nil {
			return ocispec.Descriptor{}, fmt.Errorf("error getting tar header: %w", err)
		}

		// skip all directories
		if hdr.FileInfo().IsDir() {
			continue
		}

		fname := hdr.Name
		if !opts.Strict {
			fname = path.Clean(fname)
		}

		task.Info(hdr.Name)
		log := opts.Log.With("filename", fname, "size", hdr.Size)
		log.DebugContext(ctx, "Current stage", "stage", currentStage)

		switch {
		case fname == ocispec.ImageLayoutFile:
			if err := consumeOCILayout(tr); err != nil {
				return ocispec.Descriptor{}, err
			}
			if opts.Strict {
				// oci-layout is expected first
				if currentStage != stageOCILayout {
					return ocispec.Descriptor{}, fmt.Errorf("expected the first file to be named %q", ocispec.ImageLayoutFile)
				}
				currentStage++
			}

		case fname == ocispec.ImageIndexFile:
			if indexDesc != nil {
				// silently ignore extra index.json files
				continue
			}

			catalog, err := consumeIndexJSON(tr)
			if err != nil {
				return ocispec.Descriptor{}, err
			}

			// initialize the progress UI
			ddSize := catalog.Annotations[encoding.AnnotationLayerSizeDeduplicated]
			if ddSize == "" {
				// <ace-dt v1.13 serialized files will not have this annotation so we need to check it for backwards compatibility
				// we will set it to 0
				ddSize = "0"
			}
			totalDeduplicatedSize, err := strconv.Atoi(ddSize)
			if err != nil {
				return ocispec.Descriptor{}, fmt.Errorf("getting the total deduplicated size: %w", err)
			}
			progress.Update(0, int64(totalDeduplicatedSize))

			// filter on ocispec.AnnotationRefName
			var desc *ocispec.Descriptor
			for i, d := range catalog.Manifests {
				if _, ok := d.Annotations[ocispec.AnnotationRefName]; ok {
					if desc != nil {
						// multiple name references
						// ambiguous index.json
						return ocispec.Descriptor{}, fmt.Errorf("expected one manifest in %q with %q set but found a second at %d", ocispec.ImageIndexFile, ocispec.AnnotationRefName, i)
					}
					desc = &catalog.Manifests[0]
				}

				// start by tracking the index manifest
				if err := tracker.NotifyManifest(ctx, d); err != nil {
					return ocispec.Descriptor{}, errors.Join(err, fmt.Errorf("%d missing blobs", len(tracker.MissingBlobs())))
				}
			}

			// if we only have one just use it
			if len(catalog.Manifests) == 1 {
				desc = &catalog.Manifests[0]
			}

			if desc == nil {
				return ocispec.Descriptor{}, fmt.Errorf("multiple manifests in index.json, but no manifest with %s was set", ocispec.AnnotationRefName)
			}

			if opts.Strict {
				// second we expect the index.json file
				if currentStage != stageIndexJSON {
					return ocispec.Descriptor{}, fmt.Errorf("expected the second file to be named %q", ocispec.ImageIndexFile)
				}
				currentStage++
			}
			indexDesc = desc

		case path.Dir(path.Dir(fname)) == "blobs":
			if err := consumeBlob(ctx, fname, hdr.Size, tr, tracker, remoteStorage, cacheStorage); err != nil {
				return ocispec.Descriptor{}, err
			}
			if opts.Strict {
				if currentStage != stageBlob {
					return ocispec.Descriptor{}, fmt.Errorf("expected the third file onward to be a blob")
				}
				// stay in blobs stage forever
				// TODO verify that the ordering is depth-first.  Meaning that we always see the necessary manifests before the blobs for the manifest.
			}
			// update the progress with the blob size that was deserialized
			progress.Update(hdr.Size, 0)
		default:
			if opts.Strict {
				return ocispec.Descriptor{}, fmt.Errorf("unexpected file %q", hdr.Name)
			}
			log.InfoContext(ctx, "Ignoring file", "name", hdr.Name)
		}
		opts.RootUI.Infof("read %s", print.Bytes(int64(*cw)))
	}

	if indexDesc == nil {
		return ocispec.Descriptor{}, fmt.Errorf("missing %q file", ocispec.ImageIndexFile)
	}

	if missing := tracker.MissingBlobs(); len(missing) != 0 {
		// log the missing blobs from all manifests
		opts.Log.InfoContext(ctx, "Missing blobs", "missing", missing)
		return ocispec.Descriptor{}, fmt.Errorf("%d missing blobs", len(missing))
	}

	opts.RootUI.Infof("Digest: %s", indexDesc.Digest)

	return *indexDesc, src.Close()
}

func consumeOCILayout(r io.Reader) error {
	// use oci-layout file as a sanity check and error if it is not right
	// does not get sent to the registry or processed further (yet)
	// future systems might need the version for backwards compatibility.
	var layout ocispec.ImageLayout
	if err := json.NewDecoder(r).Decode(&layout); err != nil {
		return fmt.Errorf("error unmarshalling OCI Layout file: %w", err)
	}
	if layout.Version != ocispec.ImageLayoutVersion {
		return fmt.Errorf("error improper imageLayoutVersion: %s", layout.Version)
	}

	return nil
}

func consumeIndexJSON(r io.Reader) (*ocispec.Index, error) {
	raw, err := io.ReadAll(r)
	if err != nil {
		return nil, fmt.Errorf("reading %s: %w", ocispec.ImageIndexFile, err)
	}

	index := &ocispec.Index{}
	if err := json.Unmarshal(raw, index); err != nil {
		return nil, err
	}
	return index, nil
}

func consumeBlob(ctx context.Context,
	fname string, size int64, r io.Reader,
	tracker *encoding.TaggableTracker,
	remoteStorage, cache content.Storage,
) error {
	log := logger.FromContext(ctx)

	// extract the digest from the filename
	// This is the algorithm+digest that at will be used to refer to this blob.
	// We support other algorithms points to the same blob by way of having a different file in the blobs folder.
	// We can use hard link or symbolic links in the tar archive to de-duplicate data that is the same (but different digest algorithms)
	h := digest.NewDigestFromHex(path.Base(path.Dir(fname)), path.Base(fname))

	log.With("digest", h)

	blobDesc := ocispec.Descriptor{
		MediaType: "application/octet-stream",
		Digest:    h,
		Size:      size,
	}

	// check to see if the registry already has this blob
	exists, err := remoteStorage.Exists(ctx, blobDesc)
	if err != nil {
		return fmt.Errorf("checking existence of a blob: %w", err)
	}

	if manDesc := tracker.KnownTaggable(h); manDesc != nil {
		// TODO condition this on a maximum size (but that would fail to work on JFrog Artifactory)

		data, err := content.ReadAll(r, *manDesc)
		if err != nil {
			return fmt.Errorf("reading data to populate the cache: %w", err)
		}

		// optimization (required for JFrog Artifactory)
		err = cache.Push(ctx, *manDesc, bytes.NewReader(data))
		switch {
		case errors.Is(err, errdef.ErrAlreadyExists):
		case err != nil:
			return fmt.Errorf("populating cache with manifest: %w", err)
		}

		// While we might have a descriptor for a manifest.  Technically it could be a blob as well.
		// So we upload the manifest data as a blob
		r = bytes.NewReader(data)
	}

	if !exists {
		log.InfoContext(ctx, "Transferring blob", "name", fname)
		if err := remoteStorage.Push(ctx, blobDesc, r); err != nil {
			return fmt.Errorf("pushing blob: %w", err)
		}
	}

	// Now that the blobs are all handled properly.
	// now the hard part...
	// Figure out which manifests are free to be sent to the registry (when all their dependents (manifests and blobs) are present)

	return tracker.AddBlob(ctx, h)
}

func isGzip(head []byte) bool {
	// Gzip magic numbers: 1F 8B
	return len(head) > 1 && head[0] == 0x1F && head[1] == 0x8B
}

func isZstd(head []byte) bool {
	// Zstd magic numbers: 28 B5 2F FD
	return len(head) > 3 && head[0] == 0x28 && head[1] == 0xB5 && head[2] == 0x2F && head[3] == 0xFD
}
